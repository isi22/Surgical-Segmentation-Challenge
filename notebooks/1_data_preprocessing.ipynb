{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5PBAOTX4kl7"
      },
      "source": [
        "# Surgical Tool Segmentation: Dataset Pre-processing\n",
        "\n",
        "This project uses the SAR-RARP50 dataset, which contains 50 video segments from the suturing phase of Robotic Assisted Radical Prostatectomy (RARP) procedures. The dataset was introduced for the EndoVis 2022 Challenge by Dimitris Psychogyios, Beatrice Van Amsterdam, Emanuele Colleoni and Danail Stoyanov. It includes both [training](https://rdr.ucl.ac.uk/articles/dataset/SAR-RARP50_train_set/24932499) and [test](https://rdr.ucl.ac.uk/articles/dataset/SAR-RARP50_test_set/24932499) splits.\n",
        "\n",
        "The data for each of the 50 surgical clips is distributed as a `.zip` file. Each archive contains the raw video_left.avi file and corresponding segmentation masks (`.png` files) (action annotations are also provided, but will not be used for this segmentation project).\n",
        "\n",
        "To prepare the data for use, two pre-processing steps are required:\n",
        "\n",
        "1. **Unzip Archives:** Each `video_XX.zip` file must be extracted into its own corresponding `video_XX` directory.\n",
        "\n",
        "2. **Extract Frames:** The `.avi` video files must be sampled into individual RGB frames at a rate of `1 Hz`. This is necessary to align each frame with its corresponding segmentation mask.\n",
        "\n",
        "The directory structure before and after unzipping is as follows:\n",
        "\n",
        "**Initial Structure:**\n",
        "```python\n",
        "data/\n",
        "└── train_dataset\n",
        "    └── video_01.zip\n",
        "    └── ...\n",
        "    └── video_40.zip\n",
        "└── test_dataset\n",
        "    └── video_41.zip\n",
        "    └── ...\n",
        "    └── video_50.zip\n",
        "```\n",
        "\n",
        "**After Unzipping:**\n",
        "```python\n",
        "data/\n",
        "└── train_dataset\n",
        "    └── video_XX.zip\n",
        "        └── action_continuous.txt\n",
        "        └── action_discrete.txt\n",
        "        └── segmentation\n",
        "            └──000000000.png\n",
        "            └──\n",
        "            └──nnnnnnnnnn.png\n",
        "        └── video_left.avi\n",
        "    └── ...\n",
        "└── test_dataset\n",
        "    └── video_XX.zip\n",
        "        └── action_continuous.txt\n",
        "        └── action_discrete.txt\n",
        "        └── segmentation\n",
        "            └──000000000.png\n",
        "            └──\n",
        "            └──nnnnnnnnnn.png\n",
        "        └── video_left.avi\n",
        "    └── ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "loNobsMb5vQu"
      },
      "outputs": [],
      "source": [
        "# !pip install monai\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3TLtecg42uL"
      },
      "source": [
        "## 1. Setup and Configuration\n",
        "\n",
        "This section mounts Google Drive where I have stored the datasets, and clones the official SAR-RARP50 toolkit.\n",
        "\n",
        "**What is the SAR-RARP50 Toolkit?**\n",
        "\n",
        "The [SAR-RARP50-evaluation repository](https://github.com/surgical-vision/SAR_RARP50-evaluation) is a companion toolkit created by the dataset authors. It provides helper scripts to automate common data handling tasks. For the pre-processing step, we use its unpack script to extract video frames at a precise frequency, ensuring they align perfectly with the provided segmentation masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s10CXDE4wMJ",
        "outputId": "b4a8588f-b300-4b5c-eb1c-b6fbecf19d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Toolkit repository already exists.\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive to access the project files and dataset ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/Colab Notebooks/Surgical_Tool_Segmentation'\n",
        "DATA_ROOT = os.path.join(PROJECT_ROOT, 'data')\n",
        "TOOLKIT_REPO_PATH = os.path.join(PROJECT_ROOT, 'SAR_RARP50-evaluation') # Path to the SAR-RARP50 toolkit repository\n",
        "\n",
        "# --- Paths to the training and test set directories ---\n",
        "train_path = os.path.join(DATA_ROOT, 'train_dataset')\n",
        "test_path = os.path.join(DATA_ROOT, 'test_dataset')\n",
        "\n",
        "# --- Frame Extraction Frequency ---\n",
        "# The ground-truth segmentation masks for this dataset were created for frames\n",
        "# sampled at a rate of 1 frame per second (1 Hz). Thus, we will use the same\n",
        "# sampling frequency for our RGB frames\n",
        "EXTRACTION_FREQUENCY = 1\n",
        "\n",
        "# --- Clone the Official Toolkit Repository ---\n",
        "# Check if it already exists to prevent re-downloading\n",
        "if not os.path.exists(TOOLKIT_REPO_PATH):\n",
        "  !git clone https://github.com/surgical-vision/SAR_RARP50-evaluation {TOOLKIT_REPO_PATH}\n",
        "else:\n",
        "  print(\"Toolkit repository already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qecKuYC-5-31"
      },
      "source": [
        "## 2. Unzip Video Files\n",
        "\n",
        "This step finds all `video_XX.zip` files in the train_dataset and test_dataset folders and extracts each one into a new, corresponding directory (e.g., `video_01.zip` is extracted to a folder named `video_01`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWO_M2bN6Ag4",
        "outputId": "f9b1170e-90d7-4de7-f300-89091740c001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 54 zip files to extract.\n",
            "All files have been successfully unzipped.\n"
          ]
        }
      ],
      "source": [
        "# --- Find all .zip files ---\n",
        "all_zips = glob.glob(f'{train_path}/*.zip') + glob.glob(f'{test_path}/*.zip')\n",
        "\n",
        "print(f\"Found {len(all_zips)} zip files to extract.\")\n",
        "\n",
        "# --- Loop through each zip file and extract it ---\n",
        "for zip_file_path in all_zips:\n",
        "  base_name = os.path.splitext(os.path.basename(zip_file_path))[0]\n",
        "  output_dir = os.path.join(os.path.dirname(zip_file_path), base_name)\n",
        "\n",
        "  # Only unzip if the output directory doesn't already exist\n",
        "  if not os.path.exists(output_dir):\n",
        "    !unzip -q {zip_file_path} -d {output_dir}\n",
        "\n",
        "print(\"All files have been successfully unzipped.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOqiWMGZ6XLS"
      },
      "source": [
        "## 3. Extract Image Frames from Videos\n",
        "\n",
        "Now that the `.avi` files are available, this step will recursively find all `video_left.avi` files and sample them into individual `.png` image frames at the frequency set in the configuration step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYhd7zGq6jFd",
        "outputId": "d8121188-1f71-447b-eb5b-b8375fa8e1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Surgical_Tool_Segmentation/SAR_RARP50-evaluation\n",
            "Found 54 video directories to process.\n",
            "\n",
            "--- Skipping: video_41 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_42 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_43 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_44 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_45 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_46 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_47 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_48 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_49 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_50 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_01 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_02 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_03 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_04 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_05 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_06 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_07 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_08 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_09 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_10 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_11_1 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_11_2 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_12 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_13 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_14 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_15_1 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_15_2 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_16 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_17_1 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_17_2 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_18 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_19 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_20 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_21 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_22 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_23 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_24 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_25 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_26 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_27 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_28 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_29_1 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_29_2 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_30 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_31 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_32 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_33 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_34 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_35 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_36 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_37 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_38 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_39 (already processed and verified) ---\n",
            "\n",
            "--- Skipping: video_40 (already processed and verified) ---\n",
            "\n",
            "All videos have been processed and verified.\n"
          ]
        }
      ],
      "source": [
        "# --- Setup ---\n",
        "# Change the notebook's current working directory to the toolkit's folder\n",
        "%cd {TOOLKIT_REPO_PATH}\n",
        "\n",
        "# --- Get a list of video directories ---\n",
        "all_paths = glob.glob(f'{DATA_ROOT}/*_dataset/video_*')\n",
        "all_video_dirs = [path for path in all_paths if os.path.isdir(path)]\n",
        "all_video_dirs.sort() # Sort the list for consistent processing order\n",
        "\n",
        "print(f\"Found {len(all_video_dirs)} video directories to process.\")\n",
        "\n",
        "# --- Loop, Extract, and Verify ---\n",
        "for video_dir in all_video_dirs:\n",
        "  video_name = os.path.basename(video_dir)\n",
        "  segmentation_path = os.path.join(video_dir, 'segmentation')\n",
        "  images_path = os.path.join(video_dir, 'rgb')\n",
        "\n",
        "  # --- 1. Check if the 'rgb' directory already exists. ---\n",
        "  should_skip = False\n",
        "  if os.path.exists(images_path):\n",
        "    # If it exists, check if its contents are complete.\n",
        "    segmentation_files = set(os.listdir(segmentation_path))\n",
        "    extracted_images = set(os.listdir(images_path))\n",
        "    if segmentation_files.issubset(extracted_images):\n",
        "      print(f\"\\n--- Skipping: {video_name} (already processed and verified) ---\")\n",
        "      should_skip = True\n",
        "\n",
        "  if not should_skip:\n",
        "\n",
        "    print(f\"\\n--- Processing: {video_name} ---\")\n",
        "\n",
        "    # --- 2. Extract frames for the current video ---\n",
        "    !python -m scripts.sarrarp50 unpack \"{video_dir}\" -j4 -f {EXTRACTION_FREQUENCY} > /dev/null 2>&1\n",
        "\n",
        "    # --- 3. Verify the extracted frames ---\n",
        "    # Get the filenames of all segmentation masks\n",
        "    segmentation_files = set(os.listdir(segmentation_path))\n",
        "    # Get the filenames of all newly extracted RGB images\n",
        "    extracted_images = set(os.listdir(images_path))\n",
        "\n",
        "    # Check if every segmentation mask has a corresponding extracted image\n",
        "    if segmentation_files.issubset(extracted_images):\n",
        "        print(f\"SUCCESS: All {len(segmentation_files)} segmentation masks have a matching RGB frame.\")\n",
        "    else:\n",
        "        # Find which files are missing\n",
        "        missing_files = segmentation_files - extracted_images\n",
        "        print(f\"ERROR: Verification failed for {video_name}.\")\n",
        "        print(f\"Missing {len(missing_files)} frame(s): {list(missing_files)[0]}\")\n",
        "\n",
        "print(\"\\nAll videos have been processed and verified.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVo2i6sAssep"
      },
      "source": [
        "## Aggregate Files and Create New Archives\n",
        "\n",
        "The following steps will streamline the dataset for easier use in the main training notebook.\n",
        "\n",
        "1.  **Aggregate Files:** All `.png` image frames and segmentation masks from the individual `video_XX` folders will be copied into new, top-level `all_rgb` and `all_segmentation` folders inside their respective `train_dataset` and `test_dataset` directories. Files will be renamed (e.g., `video_01_000000000.png`) to ensure there are no name conflicts.\n",
        "\n",
        "2.  **Create New Zip Archives:** New archives (`training_dataset.zip` and `test_dataset.zip`) will be created in the `data` directory. These will contain **only** the aggregated `all_rgb` and `all_segmentation` folders, making the data much faster to copy and load in future sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1rQwM4Hs7_W"
      },
      "outputs": [],
      "source": [
        "train_zip_output_path = os.path.join(DATA_ROOT, 'train_dataset.zip')\n",
        "test_zip_output_path = os.path.join(DATA_ROOT, 'test_dataset.zip')\n",
        "\n",
        "# --- 2. Helper function to create the flat archive ---\n",
        "def create_flat_archive(source_dir, output_zip_path):\n",
        "    \"\"\"\n",
        "    Finds all rgb/segmentation files in a nested directory and writes them\n",
        "    to a flat structure within a new zip file.\n",
        "    \"\"\"\n",
        "    # Find all the .png files we need to archive\n",
        "    rgb_files = glob.glob(os.path.join(source_dir, 'video_*', 'rgb', '*.png'))\n",
        "    seg_files = glob.glob(os.path.join(source_dir, 'video_*', 'segmentation', '*.png'))\n",
        "    all_files = rgb_files + seg_files\n",
        "\n",
        "    print(f\"Found {len(all_files)} files to archive in {os.path.basename(source_dir)}.\")\n",
        "\n",
        "    # Open the zip file in write mode with compression\n",
        "    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # Loop through all files with a progress bar\n",
        "        for file_path in tqdm(all_files, desc=f\"Zipping {os.path.basename(output_zip_path)}\"):\n",
        "            # --- Construct the new path inside the archive ---\n",
        "            parts = file_path.split(os.sep)\n",
        "            original_filename = parts[-1]\n",
        "            file_type_folder = parts[-2] # 'rgb' or 'segmentation'\n",
        "            video_name = parts[-3] # 'video_XX'\n",
        "\n",
        "            # Create the new filename to avoid conflicts\n",
        "            new_filename = f\"{video_name}_{original_filename}\"\n",
        "\n",
        "            # Create the path as it will appear inside the zip file\n",
        "            archive_path = os.path.join(f\"all_{file_type_folder}\", new_filename)\n",
        "\n",
        "            # Write the file to the archive under its new path\n",
        "            zipf.write(filename=file_path, arcname=archive_path)\n",
        "\n",
        "# --- 3. Execute the archiving process ---\n",
        "print(\"Starting archive creation process...\")\n",
        "start_time = time.time()\n",
        "\n",
        "create_flat_archive(train_path, train_zip_output_path)\n",
        "create_flat_archive(test_path, test_zip_output_path)\n",
        "\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "\n",
        "print(f\"\\n New zip archives created successfully. Total time: {duration:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggzyWRvixXjy"
      },
      "outputs": [],
      "source": [
        "# --- Define paths for aggregated folders ---\n",
        "agg_train_rgb_path = os.path.join(train_path, 'all_rgb')\n",
        "agg_train_seg_path = os.path.join(train_path, 'all_segmentation')\n",
        "agg_test_rgb_path = os.path.join(test_path, 'all_rgb')\n",
        "agg_test_seg_path = os.path.join(test_path, 'all_segmentation')\n",
        "\n",
        "# --- Function to find, rename, and copy files ---\n",
        "def aggregate_files(source_dir, dest_rgb_dir, dest_seg_dir):\n",
        "    \"\"\"Copies and renames files from nested video folders to flat directories.\"\"\"\n",
        "    # --- Get a list of video directories ---\n",
        "    all_paths = glob.glob(f'{source_dir}/video_*')\n",
        "    all_video_dirs = [path for path in all_paths if os.path.isdir(path)]\n",
        "    all_video_dirs.sort() # Sort the list for consistent processing order\n",
        "\n",
        "    for video_dir in all_video_dirs:\n",
        "        video_name = os.path.basename(video_dir)\n",
        "\n",
        "        # Aggregate RGB images\n",
        "        rgb_files = glob.glob(os.path.join(video_dir, 'rgb', '*.png'))\n",
        "        for f_path in rgb_files:\n",
        "            filename = os.path.basename(f_path)\n",
        "            new_filename = f\"{video_name}_{filename}\"\n",
        "            shutil.copy(f_path, os.path.join(dest_rgb_dir, new_filename))\n",
        "\n",
        "        # Aggregate segmentation masks\n",
        "        seg_files = glob.glob(os.path.join(video_dir, 'segmentation', '*.png'))\n",
        "        for f_path in seg_files:\n",
        "            filename = os.path.basename(f_path)\n",
        "            new_filename = f\"{video_name}_{filename}\"\n",
        "            shutil.copy(f_path, os.path.join(dest_seg_dir, new_filename))\n",
        "\n",
        "# --- Run the aggregation process ---\n",
        "aggregate_files(train_path, agg_train_rgb_path, agg_train_seg_path)\n",
        "aggregate_files(test_path, agg_test_rgb_path, agg_test_seg_path)\n",
        "\n",
        "print(\"\\n File aggregation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7_YLWGst5Zp",
        "outputId": "808e956a-2515-41b7-ee2e-1b617f9c4be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " New zip folders created successfully.\n"
          ]
        }
      ],
      "source": [
        "# --- Create the training_dataset.zip folder ---\n",
        "! (cd \"{train_path}\" && zip -qr \"{train_path}.zip\" all_rgb all_segmentation)\n",
        "\n",
        "# --- Create the test_dataset.zip folder ---\n",
        "! (cd \"{test_path}\" && zip -qr \"{test_path}.zip\" all_rgb all_segmentation)\n",
        "\n",
        "print(\"\\n New zip folders created successfully.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
